# Проект по ML
## Условия проекта
Выбрать любой сайт (например, avito.ru, cian.ru, drom.ru, auto.ru, auction.ru и др. (кроме wolmar.ru))

Извлечь с выбранного сайта данные при помощи языка программирования Python 3. Полученные данные должны содержать как минимум по одному типу бинарных (например, продан товар или нет), категориальных (какого цвета машина, сколько комнат в квартире, из какого металла монета и т.д.), числовых/количественных (например сколько стоит, сколько лет и т.д.) признаков. Всего должно быть не менее 5000 записей.

Предобработать данные (удалить или заполнить пропуски, выявить ошибки в данных и т.д.). Визуализировать предобработанные данные различными способами (распределение признаков и зависимости между ними), при этом использовать минимум три признака, а также минимум три взаимодействия между признаками. В результате визуализации предложить минимум три гипотезы (например, какая связь между возрастом автомобиля (квартиры) и ценой).

Выбрать целевую переменную для предсказания и обучить минимум 3 модели машинного обучения (при помощи библиотеки scikit-learn); при обучении использовать подбор гиперпараметров, кросс-валидацию и актуальные метрики в соответствии с задачей предсказания.
## Реализация проекта
Код и собранные данные лежат в данном репозитории.

### Сбор данных
* Были собраны данные по ноутбукам с сайта [DNS](https://www.dns-shop.ru/catalog/17a892f816404e77/noutbuki/).
* Для сбора использовались пакеты `Selenuim` и `BeautifulSoup`.
* В результате было собрано 8004 объекта, где количество признаков — 86
* Среди призанаков были 
    + Бинарные (`Игровой ноутбук`, `Имеет сенсорный экран` и т.д.)
    + Количественные (`Цена`, `Плотность пикселей (ppi)` и т.д.)
    + Категориальные (`Модель встроенной видеокарты`, `Материал корпуса` и т.д.)
### Визуализация признаков и зависимостей между ними
Визуализированы (пропуски удалялись):
* Распределение веса ноутбуков (Box plot) 
    + Медиана — 1.7 кг
* Распределение материалов корпусов (Pie chart) 
    + Около трети — пластик
    + Немного меньше трети — алюминий
* Cтоимость игровых ноутбуков и неигровых ноутбуков (Histogram)
    + Игровые ноутбуки в среднем дороже
* Распределение дискретных видокарт у игровых и у неигровых ноутбуков (Bar chart)
    + Взаимосвязь между категориальным (бинарной, `Игровой ноутбук`) и категориальным (`Модель дискретной видеокарты`) признаками
    + У игровых чаще встречается GeForce RTX 3060
    + У неигровых — GeForce GTX 1650
* Корреляция между яркостью (Кд/М²) и плотностью пикселей (ppi)
    + Взаимосвязь между количественным (`Яркость (Кд/М²)`) и количественным (`Плотность пикселей (ppi)`) признаками
    + Корреляция между яркостью и плотностью пикселей наблюдается
* Зависимость между ценой и типом оперативной памяти
    + Взаимосвязь между количественным (`Цена`) и категориальным (`Тип оперативной памяти`) признаками
    + Большая цена у ноутбуков с DDR5
    + Меньшая цена у ноутбуков с DDR3L, LPDDR3, DDR3
### Обучение моделей
В качестве целевой переменной была выбрана `Цена`, соответственно перед нами задача регрессии.
В качестве признаков, по которым будет вестись предсказание, были выбраны следующие 9:
* `Год релиза`
* `Диагональ экрана (дюйм)`
* `Максимальная частота обновления экрана (Гц)`
* `Частота процессора (ГГц)`
* `Объем оперативной памяти (Гб)`
* `Общий объем SSD (Гб)`
* `Максимальный объем памяти (Гб)`
* `Автоматическое увеличение частоты (ГГц)`
* `Максимальное число потоков`

Для решения задачи регрессии были выбраны следующие модели:
* `GradientBoostingRegressor`
* `LinearRegression`
* `RandomForestRegressor`

Качество работы этих моделей оценивалось с помощью следующих метрик 
* R²
* MSE
* MAE

Для более точной проверки метрик использовалась кросс-валидация (4 блока). 
В результае лучшей оказалась модель `GradientBoostingRegressor` (Значения R²: 0.37, 0.14, 0.45, 0.45).
Возможно, не самые высокие показатели метрик, но это лучшее, что получилось добиться на этих данных (без `GridSearchCV`).
Далее с помощью `GridSearchCV` был проведен поиск параметров, дающих лучшие показатели метрик. 
В итоге лучшими значениями параметров оказались:
* `max_depth`: 3
* `min_samples_leaf`: 15,
* `min_samples_split` 2
* `n_estimators`: 100

При этом метрики получились следующими:
* R²: 0.42 (у стандартной модели `GradientBoostingRegressor` — 0.4)
* Корень из MSE: 27390 (у стандартной модели `GradientBoostingRegressor` — 27846)
* MAE: 18218 (у стандартной модели `GradientBoostingRegressor` — 18396)
